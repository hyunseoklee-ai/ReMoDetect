<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>ReMoDetect</title>
    <meta name="author" content="MAC" />
    <meta name="generator" content="Org Mode" />
    <style>
        .title  { text-align: center;
                 margin-bottom: .2em; }
        .subtitle { text-align: center;
                    font-size: medium;
                    font-weight: bold;
                    margin-top:0; }
        .todo   { font-family: monospace; color: red; }
        .done   { font-family: monospace; color: green; }
        .priority { font-family: monospace; color: orange; }
        .tag    { background-color: #eee; font-family: monospace;
                   padding: 2px; font-size: 80%; font-weight: normal; }
        .timestamp { color: #bebebe; }
        .timestamp-kwd { color: #5f9ea0; }
        .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
        .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
        .org-center { margin-left: auto; margin-right: auto; text-align: center; }
        .underline { text-decoration: underline; }

        .figure-slarge img {
            width: 100%; /* width for large figure */
            display: block;
            margin: 0 auto; /* center image */
        }

        .figure-large img {
            width: 75%; /* width for large figure */
            display: block;
            margin: 0 auto; /* center image */
        }

        .figure-medium img {
            width: 50%; /* width for medium figure */
            display: block;
            margin: 0 auto; /* center image */
        }

        /* other figure styles can go here */

        @media screen and (max-width: 600px) { /* adjust the pixel value based on your design */
        .figure-slarge img, .figure-large img, .figure-medium img {
            width: 100%; /* full width on smaller screens */
            }
        }

        img {
            max-width: 100%;
            height: auto; /* Maintains the aspect ratio */
            padding-right: 2%;
            vertical-align: middle;
        }

        figure {
            text-align: center;
            margin-left: auto;
            margin-right: auto;
        }

        table { table-layout: fixed; }
        td {
            width: 50%;
        }

        body {
            max-width: 980px;
            padding: 10px;
            padding-top: 25px;
            padding-bottom: 40px;
            margin: 0 auto;
            font-family: 'Noto Sans KR', sans-serif;
            font-weight: 375;
            background-color: #fdfdfd;
            line-height: 1.3;
            font-size: 17.5px;
        }

        strong{
            font-family: 'Noto Sans KR', sans-serif;
            font-weight: 500;
        }

        h1 {
            margin-top: 0;
            line-height: 1;
            font-weight: 500;
        }

        h2 {
            border-bottom: 1px solid #ddd;
            margin-top: 1.3em;
            margin-bottom: 0em;
            padding-bottom: 4px;
            font-weight: 500;
        }

        li {
           margin: 7px 0;
          }

        a { 
            color:#1772d0; 
            text-decoration-line: none;
        }
        a:hover {
            color:#f09228; 
        }

        .footer {
            padding-top: 10px;
        }

        .footer-cover {
            background-color: #f5f5f5;
            padding-left: 0;
            padding-right: 0;
            margin-top: 50px;
            height: 80px;
        }

        .responsive-iframe {
            width: 650px;
            height: 350px;
            max-width: 100%;
            margin: auto; /* Center the iframe */
        }

        .responsive-iframe iframe {
            width: 100%;
            height: 100%;
        }

        @media screen and (max-width: 650px){
            .responsive-iframe {
                max-width: 100%;
            }
        }

    </style>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/notosanskr.css">
  </head>
  <body>
  	<br>
  	<br>
  	<span style="font-size:40px; color:#000;">
            <b>
            	<center>
                &#128373 ReMoDetect: Reward Models <br>
                Recognize Aligned LLM's Generations
               </center>
            </b>
        </span>
		</span>
		<br>
    <table align=center width=600px>
        <tr>
        <center>
        <div style="font-size:20px; text-align: center">
            <a href="https://hyunseoklee-ai.github.io/">Hyunseok Lee</a><sup>* 1</sup>, &nbsp;
            <a href="https://jihoontack.github.io">Jihoon Tack</a><sup>* 1</sup>, &nbsp;
            <a href='https://alinlab.kaist.ac.kr/shin.html'>Jinwoo Shin</a><sup>1</sup>
        </div>

        <br>

        <span style="font-size:18px; text-align: center">
            <sup>1</sup> Korea Advanced Institute of Science and Technology <br>
            <sup>*</sup> Equal Contribution
        </span>

        <br>
        <br>

        <div class="paper-btn-parent">
            <a href="https://arxiv.org/abs/2405.17382">
            [<b>Paper</b>]
            </a>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/hyunseoklee-ai/reward_llm_detect">
            [<b>Code</b>]
            </a>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://arxiv.org/abs/2405.17382">
            [<b>Twitter</b>]
            </a>
            </div>
        </center>
        </tr>
        </table>

    <!-- <div id="outline-container-orgc5d597d" class="outline-2">
    <h2 id="orgc5d597d">&#x1F6A7 Demo: Detect LLM Generated Texts using ReMoDetect! &#x1F6A7</h2>
    <div class="outline-text-2" id="text-orgc5d597d">
    <p style="text-align:justify">
        &#x1F6A7 in progress... &#x1F6A7
    </p> -->

    <div id="outline-container-orgc5d597d" class="outline-2">
    <h2 id="orgc5d597d">Abstract</h2>
    <div class="outline-text-2" id="text-orgc5d597d">
    <p style="text-align:justify">
        The remarkable capabilities and easy accessibility of large language models (LLMs) have significantly increased societal risks (e.g., fake news generation), necessitating the development of LLM-generated text (LGT) detection methods for safe usage. However, detecting LGTs is challenging due to the vast number of LLMs, making it impractical to account for each LLM individually; hence, it is crucial to identify the common characteristics shared by these models. In this paper, we draw attention to a common feature of recent powerful LLMs, namely the alignment training, i.e., training LLMs to generate human-preferable texts. Our key finding is that as these aligned LLMs are trained to maximize the human preferences, they generate texts with higher estimated preferences even than human-written texts; thus, such texts are easily detected by using the reward model (i.e., an LLM trained to model human preference distribution). Based on this finding, we propose two training schemes to further improve the detection ability of the reward model, namely (i) continual preference fine-tuning to make the reward model prefer aligned LGTs even further and (ii) reward modeling of Human/LLM mixed texts (a rephrased texts from human-written texts using aligned LLMs), which serves as a median preference text corpus between LGTs and human-written texts to learn the decision boundary better. We provide an extensive evaluation by considering six text domains across twelve aligned LLMs, where our method demonstrates state-of-the-art results. 
    </p>
    

    <div id="outline-container-orgc5d597d" class="outline-2">
    <h2 id="orgc5d597d">&#128269 Observation: Reward Models Recognize Aligned LLM's Generations</h2>
    <div class="outline-text-2" id="text-orgc5d597d">

    <figure class="figure-slarge">
     <img src="resources/tsne.png">
    </figure>
    <figure class="figure-slarge">
     <img src="resources/histo.png">
    </figure>
    
    <p style="text-align:justify">
        <strong>Observation</strong>: As aligned LLMs are optimized to maximize human preferences, they generate texts with higher predicted rewards even compared to human-written texts. 
        We visualize the (i) t-SNE of the reward model's final feature and the (ii) histogram of the predicted reward score. Here, `Machine' indicates the text generated by GPT3.5/GPT4 Turbo, Llama3-70B instruct, and Claude3 Opus.
        Based on this, one can easily distinguish LLM-generated texts from human-written texts by simply using the predicted score of the reward model as the detection criteria, e.g., AUROC of 92.8% when detecting GPT4 generated texts.
    </p>


    <div id="outline-container-orgc5d597d" class="outline-2">
    <h2 id="orgc5d597d">&#128373 ReMoDetect: Detecting LLMâ€™s Generations using Reward Models</h2>
    <div class="outline-text-2" id="text-orgc5d597d">

    <figure class="figure-slarge">
  	 <img src="resources/concept_figure.png">
	</figure>

    <p style="text-align:justify">
    We propose ReMoDetect, a novel and effective aligned LGT detection framework using the reward model. In a nutshell, ReMoDetect is comprised of two training components to improve the detection ability of the reward model. First, to further increase the separation of the predicted reward between LGTs and human-written texts, we continually fine-tune the reward model to predict even higher reward scores for LGTs compared to human-written-texts while preventing the overfitting bias using the replay technique. Second, we generate an additional preference dataset for reward model fine-tuning, namely the Human/LLM mixed text; we partially rephrase the human-written text using LLM. Here, such texts are used as a median preference corpus among the human-written text and LGT corpora, enabling the detector to learn a better decision boundary. 
    </p>

    <div id="outline-container-orgc5d597d" class="outline-2">
    <h2 id="orgc5d597d">&#128202 Experimental Results</h2>
    <div class="outline-text-2" id="text-orgc5d597d">
    
    <figure class="figure-slarge">
  	 <img src="resources/main_result.png">
	</figure>	

	<p style="text-align:justify">
        <strong>LGT detection performance</strong>:
	   We present the LGT detection performance of ReMoDetect and other detection baselines. Overall, ReMoDetect significantly outperforms prior detection methods by a large margin, achieving state-of-the-art performance in average AUROC.
	</p>
	<br>

    <figure class="figure-slarge">
  	     <img src="resources/gptzero.png">
	</figure>

	<p style="text-align:justify">
		<strong>Comparison with a commercial detection method</strong>: 
		We also compare ReMoDetect with a commercial LGT detection method, GPTZero, under the Fast-DetectGPT benchmark. As shown in the table above, ReMoDetect outperforms GPTZero in all considered aligned LLMs except for one in terms of the average AUROC.
	</p>
	<br>

	<figure class="figure-slarge">
  	     <img src="resources/robust_attack.png">
	</figure>

    <p style="text-align:justify">
		<strong>Robustness against rephrasing attacks</strong>: 
        One possible challenging scenario is detecting the rephrased texts by another LM (known as rephrasing attacks), i.e., first generate texts with powerful LLMs and later modify them with another LLM. 
        As shown in the above table, RoMoDetect significantly and consistently outperforms all baselines. 
    </p>
    <br>

    <figure class="figure-slarge">
         <img src="resources/robust_length.png">
    </figure>

	<p style="text-align:justify">
		<strong>Robustness on input response length</strong>: 
		We also measure the robustness of RoMoDetect on the input response length (i.e., # of words in y). Interestingly, our method can even outperform the best baseline with 71.4% fewer words, showing significant robustness on short input responses.
	</p>

    <div id="outline-container-orgc5d597d" class="outline-2">
    <h2 id="orgc5d597d">Citation</h2>
    <table width="100%" border="0" cellspacing="1" cellpadding="1" align="center">        
        <tr>
            <td width="100%" style="background-color: #EEEEEE;">
                <div style="font-size:17px;">
                    <tt>
                        @article{lee2024remodetect,<br>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title={ReMoDetect: Reward Models Recognize Aligned LLM's Generations},<br>
			    		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;author={Lee, Hyunseok and Tack, Jihoon and Shin, Jinwoo},<br>
			    		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;journal={arXiv preprint arXiv:2405.17382},<br>
			    		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;year={2024},<br>
			    		}
                    </tt>
                </div>
            </td>
        </tr>
    </table>
</div>

<h2 id="orgc5d597d"></h2>

</body>
</html>
